#                       c) Apparent prediction error (APA)
#  While running the function, also prints "in between" results.
autoscale <- function(x) {
x <- as.matrix(x)
N <- nrow(x)
scale(x) * sqrt(N / (N - 1)) # correct for N-1
}
outcomename <- all.vars(formula)[1]
predname <- all.vars(formula)[-1] # extract the predictor names
y <- autoscale(data[, outcomename])
X <- autoscale(data[, predname])
# For comparison, we compute first the linear regression solution:
beta_lin <- solve(t(X) %*% X) %*% t(X) %*% y
loss_lin <- sum((y - X %*% beta_lin)^2)
# Compute least squares recursively
alternate <- function(betas_old, loss_old, iter) {
betas_new <- t(t(sapply(seq(ncol(X)), function(j) {
xj <- cbind(X[, j])
uj <- y - cbind(X[, -j]) %*% betas_old[-j, ]
solve(t(xj) %*% xj) %*% t(xj) %*% uj
})))
loss_new <- t(y - X %*% betas_new) %*% (y - X %*% betas_new)
loss_diff <- loss_old - loss_new
cat("Iteration: ", iter,
"Current loss: ", round(loss_new, 3),
"Current change: ", loss_diff,
"\n")
if (!(abs(loss_diff) <= crititer | iter >= maxiter)) {
alternate(betas_new, loss_new, iter + 1)
} else {
betas_new
}
}
#Start alternating least squares solution starting with beta = 0
betas <- alternate(as.matrix(rep(0, ncol(X))), 10000, 0)
res <- y - X %*% betas
rss <- unname(t(res) %*% res)[1]
tss <- sum((y - mean(y))^2)
regss <- tss - rss
asf <<- list(rss, tss, regss)
betas <- t(betas)
colnames(betas) <- paste0("beta", seq_along(betas), sep = "")
asf <<- list(rss, tss, regss)
ss <- cbind("TSS" = tss, "RegSS" = regss, "RSS" = rss)
list("coefs" = betas,
"ss" = ss
)
}
data <- read_sav("D:/OneDrive/_Msc_/Semester 2/Multivar-Multidim Data Analysis/Practicals/Week 1/Cardatabinned.sav")
asd <- catregnum(Price ~ Gas + Weight, data)
asd
catregnum <- function(formula, data, crititer = 0.000000001, maxiter = 1000) {
# Args:
#   formula: an object of class "formula": a symbolic description of the model
#            to be fitted.
#   data: a data frame containing the variabless in the model. Factor variables
#         currently not supported.
#   crititer: critical value for the decrease in loss between two iterations
#   maxiter: maximum number of iterations
#
# Returns:
#   a list object with: a) The final regression coefficients
#                       b) Regression and total sum of squares
#                       c) Apparent prediction error (APA)
#  While running the function, also prints "in between" results.
autoscale <- function(x) {
x <- as.matrix(x)
N <- nrow(x)
scale(x) * sqrt(N / (N - 1)) # correct for N-1
}
outcomename <- all.vars(formula)[1]
predname <- all.vars(formula)[-1] # extract the predictor names
y <- autoscale(data[, outcomename])
X <- autoscale(data[, predname])
# For comparison, we compute first the linear regression solution:
beta_lin <- solve(t(X) %*% X) %*% t(X) %*% y
loss_lin <- sum((y - X %*% beta_lin)^2)
# Compute least squares recursively
alternate <- function(betas_old, loss_old, iter) {
betas_new <- t(t(sapply(seq(ncol(X)), function(j) {
xj <- cbind(X[, j])
uj <- y - cbind(X[, -j]) %*% betas_old[-j, ]
solve(t(xj) %*% xj) %*% t(xj) %*% uj
})))
loss_new <- t(y - X %*% betas_new) %*% (y - X %*% betas_new)
loss_diff <- loss_old - loss_new
cat("Iteration: ", iter,
"Current loss: ", round(loss_new, 3),
"Current change: ", loss_diff,
"\n")
if (!(abs(loss_diff) <= crititer | iter >= maxiter)) {
alternate(betas_new, loss_new, iter + 1)
} else {
betas_new
}
}
#Start alternating least squares solution starting with beta = 0
betas <- alternate(as.matrix(rep(0, ncol(X))), 10000, 0)
res <- y - X %*% betas
rss <- unname(t(res) %*% res)[1]
tss <- sum((y - mean(y))^2)
regss <- tss - rss
asf <<- list(rss, tss, regss)
betas <- t(betas)
colnames(betas) <- paste0("beta", seq_along(betas), sep = "")
asf <<- list(rss, tss, regss)
ss <- cbind("TSS" = tss, "RegSS" = regss, "RSS" = rss)
list("coefs" = betas,
"ss" = ss,
"apparent error" = rss / tss
)
}
data <- read_sav("D:/OneDrive/_Msc_/Semester 2/Multivar-Multidim Data Analysis/Practicals/Week 1/Cardatabinned.sav")
asd <- catregnum(Price ~ Gas + Weight, data)
asd
asd$`apparent error`
knitr::opts_chunk$set(echo = TRUE)
catregnum <- function(formula, data, crititer = 0.000000001, maxiter = 1000) {
# Args:
#   formula: an object of class "formula": a symbolic description of the model
#            to be fitted.
#   data: a data frame containing the variabless in the model. Factor variables
#         currently not supported.
#   crititer: critical value for the decrease in loss between two iterations
#   maxiter: maximum number of iterations
#
# Returns:
#   a list object with: a) The final regression coefficients
#                       b) Regression and total sum of squares
#                       c) Apparent prediction error (APA)
#  While running the function, also prints "in between" results.
autoscale <- function(x) {
x <- as.matrix(x)
N <- nrow(x)
scale(x) * sqrt(N / (N - 1)) # correct for N-1
}
outcomename <- all.vars(formula)[1]
predname <- all.vars(formula)[-1] # extract the predictor names
y <- autoscale(data[, outcomename])
X <- autoscale(data[, predname])
# For comparison, we compute first the linear regression solution:
beta_lin <- solve(t(X) %*% X) %*% t(X) %*% y
loss_lin <- sum((y - X %*% beta_lin)^2)
# Compute least squares recursively
alternate <- function(betas_old, loss_old, iter) {
betas_new <- t(t(sapply(seq(ncol(X)), function(j) {
xj <- cbind(X[, j])
uj <- y - cbind(X[, -j]) %*% betas_old[-j, ]
solve(t(xj) %*% xj) %*% t(xj) %*% uj
})))
loss_new <- t(y - X %*% betas_new) %*% (y - X %*% betas_new)
loss_diff <- loss_old - loss_new
cat("Iteration: ", iter,
"Current loss: ", round(loss_new, 3),
"Current change: ", loss_diff,
"\n")
if (!(abs(loss_diff) <= crititer | iter >= maxiter)) {
alternate(betas_new, loss_new, iter + 1)
} else {
betas_new
}
}
#Start alternating least squares solution starting with beta = 0
betas <- alternate(as.matrix(rep(0, ncol(X))), 10000, 0)
res <- y - X %*% betas
rss <- unname(t(res) %*% res)[1]
tss <- sum((y - mean(y))^2)
regss <- tss - rss
betas <- t(betas)
colnames(betas) <- paste0("beta", seq_along(betas), sep = "")
ss <- cbind("TSS" = tss, "RegSS" = regss, "RSS" = rss)
list("coefs" = betas,
"ss" = ss,
"apparent error" = rss / tss
)
}
data <- read_sav("Cardatabinned.sav")
out <- catregnum(Price ~ Gas + Weight, data)
out
out$ss[,1]/out$ss[,2]
out$ss[, 2]/out$ss[,1]
knitr::opts_chunk$set(echo = TRUE)
catregnum <- function(formula, data, crititer = 0.000000001, maxiter = 1000) {
# Args:
#   formula: an object of class "formula": a symbolic description of the model
#            to be fitted.
#   data: a data frame containing the variabless in the model. Factor variables
#         currently not supported.
#   crititer: critical value for the decrease in loss between two iterations
#   maxiter: maximum number of iterations
#
# Returns:
#   a list object with: a) The final regression coefficients
#                       b) Regression and total sum of squares
#                       c) Apparent prediction error (APA)
#  While running the function, also prints "in between" results.
autoscale <- function(x) {
x <- as.matrix(x)
N <- nrow(x)
scale(x) * sqrt(N / (N - 1)) # correct for N-1
}
outcomename <- all.vars(formula)[1]
predname <- all.vars(formula)[-1] # extract the predictor names
y <- autoscale(data[, outcomename])
X <- autoscale(data[, predname])
# For comparison, we compute first the linear regression solution:
beta_lin <- solve(t(X) %*% X) %*% t(X) %*% y
loss_lin <- sum((y - X %*% beta_lin)^2)
# Compute least squares recursively
alternate <- function(betas_old, loss_old, iter) {
betas_new <- t(t(sapply(seq(ncol(X)), function(j) {
xj <- cbind(X[, j])
uj <- y - cbind(X[, -j]) %*% betas_old[-j, ]
solve(t(xj) %*% xj) %*% t(xj) %*% uj
})))
loss_new <- t(y - X %*% betas_new) %*% (y - X %*% betas_new)
loss_diff <- loss_old - loss_new
cat("Iteration: ", iter,
"Current loss: ", round(loss_new, 3),
"Current change: ", loss_diff,
"\n")
if (!(abs(loss_diff) <= crititer | iter >= maxiter)) {
alternate(betas_new, loss_new, iter + 1)
} else {
betas_new
}
}
#Start alternating least squares solution starting with beta = 0
betas <- alternate(as.matrix(rep(0, ncol(X))), 10000, 0)
res <- y - X %*% betas
rss <- unname(t(res) %*% res)[1]
tss <- sum((y - mean(y))^2)
regss <- tss - rss
betas <- t(betas)
colnames(betas) <- paste0("beta", seq_along(betas), sep = "")
ss <- cbind("TSS" = tss, "RegSS" = regss, "RSS" = rss)
list("coefs" = betas,
"ss" = ss,
"apparent error" = rss / tss
)
}
data <- read_sav("Cardatabinned.sav")
out <- catregnum(Price ~ Gas + Weight, data)
out
knitr::opts_chunk$set(echo = TRUE)
# I have put this function outside of catregnum since it will be used later on again
autoscale <- function(x) {
# Short function which standardizes over N instead of N-1.
x <- as.matrix(x)
N <- nrow(x)
scaled <- scale(x)
autoscaled <- scaled * sqrt(N/(N-1)) # correct for N-1
return(autoscaled)
}
catregnum <- function(formula, data, crititer=0.000000001, maxiter=1000,
monitor = TRUE) {
# Performs the alternating least squares algorithm that is used by optimal
# scaling regression (CATREG). Optimal scaling level of all variables is restricted
# to "numeric".
#
# Args:
#   formula: an object of class "formula": a symbolic description of the model
#            to be fitted.
#   data: a data frame containing the variabless in the model. Factor variables
#         currently not supported.
#   crititer: critical value for the decrease in loss between two iterations
#   maxiter: maximum number of iterations
#   monitor: TRUE if "in between" results are to be printed, FALSE if not
#
# Returns:
#   a list object with: a) The final regression coefficients
#                       b) Regression and total sum of squares
#                       c) Apparent prediction error (APA)
#                       d) The multiple R-squared value
#   While running the function, also prints "in between" results.
#
outcomename <- all.vars(formula)[1]
predname <- all.vars(formula)[-1] # extract the predictor names
y <- autoscale(data[,outcomename])
X <- autoscale(data[,predname])
# For comparison, we compute first the linear regression solution:
beta_lin <-solve(t(X)%*%X)%*%t(X)%*%y
loss_lin <-sum((y - X %*% beta_lin)^2)
# .... optionally fill in extra fit measures
#Start alternating least squares solution starting with beta = 0
betas.old <- betas.new <- as.matrix(rep(0, ncol(X)))
iter <- 0
loss.diff <- 1000
if (monitor) {
cat("Iteration: ", iter,
"Current loss: ", round(sum((y - X %*% betas.old)^2), 3),
"Change: ", round(loss.diff, 3),
"\n")
}
while((abs(loss.diff) <= crititer | iter >= maxiter)==FALSE) {
for(j in 1:ncol(X)) { # Block updating of betas
xj <- X[,j]
Xj <- as.matrix(X[,-j])
uj <- y - (Xj %*% betas.new[-j])
betas.new[j] <- solve(t(xj)%*%xj)%*%(t(xj)%*%uj)
}
loss.old <- sum((y - X%*%betas.old)^2)
loss.new <- sum((y - X%*%betas.new)^2)
loss.diff <- loss.old - loss.new
iter <- iter + 1
if (monitor) {
cat("Iteration: ", iter,
"Current loss: ", round(loss.new, 3),
"Current change: ", loss.diff,
"\n")
}
betas.old <- betas.new
}
cat("\n")
SS <- c(as.numeric(t(y-mean(y))%*%(y-mean(y))),
as.numeric(t(X%*%betas.new - mean(y)) %*% (X%*%betas.new - mean(y))))
names(SS) <- c("SS.Total", "SS.Regression")
R2 <- SS[2]/SS[1]
names(R2) <- "R squared (unadjusted)"
APE <- 1 - R2
names(APE) <- "Apparent.Prediction.Error"
final.betas <- as.numeric(betas.new)
names(final.betas) <- colnames(X)
obj<-list(coefficients = final.betas,
SS = SS,
R.squared = R2,
APE = APE)
return(obj)
}
# data, obtained through dput()
cardata <- structure(list(Brand = structure(c(3L, 5L, 9L, 7L, 10L, 6L, 4L, 2L, 1L, 8L),
.Label = c("AMCEagle","BuickRegal","ChevroletChevette", "ChevroletImpala",
"DodgeColt", "DodgeDiplomat", "FortMustang", "Oldmobile98",
"PlymouthHorizon", "PontiacPhoenix"), class = "factor"),
Price = c(1, 1, 1, 2, 2, 2, 3, 3, 3, 4),
Gas = c(1, 1, 1, 1, 1, 3, 2, 2, 4, 2),
Weight = c(1, 1, 1, 2, 2, 4, 5, 4, 4, 5)),
.Names = c("Brand", "Price", "Gas", "Weight"), row.names = c(NA,-10L),
class = "data.frame",
variable.labels = structure(c("","Price ", "Gas ", "Weight "),
.Names = c("Brand", "Price", "Gas","Weight")),
codepage = 65001L)
print(cardata)
# function outcome using price as DV and Weight + Gas as IV
catreg_model <- catregnum(formula = Price ~ Gas + Weight, data = cardata)
print(catreg_model)
# linear regression using the same formula on scaled data
linreg_model <- lm(formula = Price ~ Gas + Weight,
data = as.data.frame(autoscale(cardata[,-1])))
print(linreg_model)
# testing for "near" equality of the two model coefficients
# (assuming that the intercept is dropped in the linear regression model)
all.equal(catreg_model$coefficients, linreg_model$coefficients[-1])
m1 <- lm(Price ~ Gas + Weight + 0, data)
summary(m1)
catregnum$autoscale
autoscale <- function(x) {
x <- as.matrix(x)
N <- nrow(x)
scale(x) * sqrt(N / (N - 1)) # correct for N-1
}
autoscale(data)
m1 <- lm(autoscale(Price) ~ autoscale(Gas) + autoscale(Weight) + 0, data)
summary(m1)
summary(linreg_model)
autoscale <- function(x) {
x <- as.matrix(x)
N <- nrow(x)
scale(x) * sqrt(N / (N - 1)) # correct for N-1
}
catregnum <- function(formula, data, crititer = 0.000000001, maxiter = 1000) {
# Args:
#   formula: an object of class "formula": a symbolic description of the model
#            to be fitted.
#   data: a data frame containing the variabless in the model. Factor variables
#         currently not supported.
#   crititer: critical value for the decrease in loss between two iterations
#   maxiter: maximum number of iterations
#
# Returns:
#   a list object with: a) The final regression coefficients
#                       b) Regression and total sum of squares
#                       c) Apparent prediction error (APA)
#  While running the function, also prints "in between" results.
outcomename <- all.vars(formula)[1]
predname <- all.vars(formula)[-1] # extract the predictor names
y <- autoscale(data[, outcomename])
X <- autoscale(data[, predname])
# For comparison, we compute first the linear regression solution:
beta_lin <- solve(t(X) %*% X) %*% t(X) %*% y
loss_lin <- sum((y - X %*% beta_lin)^2)
# Compute least squares recursively
alternate <- function(betas_old, loss_old, iter) {
betas_new <- t(t(sapply(seq(ncol(X)), function(j) {
xj <- cbind(X[, j])
uj <- y - cbind(X[, -j]) %*% betas_old[-j, ]
solve(t(xj) %*% xj) %*% t(xj) %*% uj
})))
loss_new <- t(y - X %*% betas_new) %*% (y - X %*% betas_new)
loss_diff <- loss_old - loss_new
cat("Iteration: ", iter,
"Current loss: ", round(loss_new, 3),
"Current change: ", loss_diff,
"\n")
if (!(abs(loss_diff) <= crititer | iter >= maxiter)) {
alternate(betas_new, loss_new, iter + 1)
} else {
betas_new
}
}
#Start alternating least squares solution starting with beta = 0
betas <- alternate(as.matrix(rep(0, ncol(X))), 10000, 0)
res <- y - X %*% betas
rss <- unname(t(res) %*% res)[1]
tss <- sum((y - mean(y))^2)
regss <- tss - rss
betas <- t(betas)
colnames(betas) <- paste0("beta", seq_along(betas), sep = "")
ss <- cbind("TSS" = tss, "RegSS" = regss, "RSS" = rss)
list("coefs" = betas,
"ss" = ss,
"apparent error" = rss / tss
)
}
data <- read_sav("Cardatabinned.sav")
out <- catregnum(Price ~ Gas + Weight, data)
out
summary(out)
data <- read_sav("Cardatabinned.sav")
out <- catregnum(Price ~ Gas + Weight, data)
out
m1 <- lm(autoscale(Price) ~ autoscale(Gas) + autoscale(Weight) + 0, data)
m1 <- lm(autoscale(Price) ~ autoscale(Gas) + autoscale(Weight) + 0, data)
cbind(m1$coefficients, out$coefs)
m1$coefficients
out$coefs
as.vector(out$coefs)
autoscale <- function(x) {
x <- as.matrix(x)
N <- nrow(x)
scale(x) * sqrt(N / (N - 1)) # correct for N-1
}
catregnum <- function(formula, data, crititer = 0.000000001, maxiter = 1000) {
# Args:
#   formula: an object of class "formula": a symbolic description of the model
#            to be fitted.
#   data: a data frame containing the variabless in the model. Factor variables
#         currently not supported.
#   crititer: critical value for the decrease in loss between two iterations
#   maxiter: maximum number of iterations
#
# Returns:
#   a list object with: a) The final regression coefficients
#                       b) Regression and total sum of squares
#                       c) Apparent prediction error (APA)
#  While running the function, also prints "in between" results.
outcomename <- all.vars(formula)[1]
predname <- all.vars(formula)[-1] # extract the predictor names
y <- autoscale(data[, outcomename])
X <- autoscale(data[, predname])
# For comparison, we compute first the linear regression solution:
beta_lin <- solve(t(X) %*% X) %*% t(X) %*% y
loss_lin <- sum((y - X %*% beta_lin)^2)
# Compute least squares recursively
alternate <- function(betas_old, loss_old, iter) {
betas_new <- t(t(sapply(seq(ncol(X)), function(j) {
xj <- cbind(X[, j])
uj <- y - cbind(X[, -j]) %*% betas_old[-j, ]
solve(t(xj) %*% xj) %*% t(xj) %*% uj
})))
loss_new <- t(y - X %*% betas_new) %*% (y - X %*% betas_new)
loss_diff <- loss_old - loss_new
cat("Iteration: ", iter,
"Current loss: ", round(loss_new, 3),
"Current change: ", loss_diff,
"\n")
if (!(abs(loss_diff) <= crititer | iter >= maxiter)) {
alternate(betas_new, loss_new, iter + 1)
} else {
betas_new
}
}
#Start alternating least squares solution starting with beta = 0
betas <- alternate(as.matrix(rep(0, ncol(X))), 10000, 0)
res <- y - X %*% betas
rss <- unname(t(res) %*% res)[1]
tss <- sum((y - mean(y))^2)
regss <- tss - rss
betas <- as.vector(t(betas))
names(betas) <- paste0("beta", seq_along(betas), sep = "")
ss <- cbind("TSS" = tss, "RegSS" = regss, "RSS" = rss)
list("coefs" = betas,
"ss" = ss,
"apparent error" = rss / tss
)
}
data <- read_sav("Cardatabinned.sav")
out <- catregnum(Price ~ Gas + Weight, data)
out
m1 <- lm(autoscale(Price) ~ autoscale(Gas) + autoscale(Weight) + 0, data)
cbind(m1$coefficients, out$coefs)
cbind(unname(m1$coefficients), out$coefs)
cbind(unname(m1$coefficients), unname(out$coefs))
cbind("LM" = unname(m1$coefficients), "CATREG" = unname(out$coefs))
cbind("LM" = unname(m1$coefficients), "CATREG" = out$coefs)
dput(data)
setwd("D:/onedrive/github/ggpol")
setwd("C:/users/frederik/documents/ggpol")
devtools::load_all()
setwd("D:/onedrive/github/ggpol")
devtools::load_all()
roxygen2::roxygenize()
